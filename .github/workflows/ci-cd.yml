name: CI/CD Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: docker.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '22'
        cache: 'npm'
        
    - name: Install dependencies and fix Prisma issues
      run: |
        # Use the Prisma fix script to handle installation issues
        ./scripts/fix-prisma.sh fix
      
    # - name: Run linting
    #   run: npm run lint
      
    # - name: Run tests
    #   run: npm test
      
    - name: Build application
      run: npm run build

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_ACCESS_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
          
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
        aws-region: us-east-1
        
    - name: Update kube config
      run: aws eks update-kubeconfig --region us-east-1 --name tech_challenge_cluster
      
    - name: Get database URL from AWS RDS
      id: database-url
      run: |
        # Get database URL dynamically from AWS RDS
        echo "üîç Getting database URL from AWS RDS..."
        
        # Get RDS instance details (dynamic parts)
        RDS_ENDPOINT=$(aws rds describe-db-instances \
          --db-instance-identifier tech-challenge-products-db \
          --query 'DBInstances[0].Endpoint.Address' \
          --output text \
          --region us-east-1)
        
        RDS_PORT=$(aws rds describe-db-instances \
          --db-instance-identifier tech-challenge-products-db \
          --query 'DBInstances[0].Endpoint.Port' \
          --output text \
          --region us-east-1)
        
        # Get credentials from GitHub secrets (static parts)
        DB_USERNAME="${{ secrets.DB_USERNAME }}"
        DB_PASSWORD="${{ secrets.DB_PASSWORD }}"
        DB_NAME="${{ secrets.DB_NAME }}"
        
        # Verify GitHub secrets are set
        if [ -z "$DB_USERNAME" ] || [ -z "$DB_PASSWORD" ] || [ -z "$DB_NAME" ]; then
          echo "‚ùå Missing required GitHub secrets!"
          echo "Please set the following secrets in your GitHub repository:"
          echo "  - DB_USERNAME"
          echo "  - DB_PASSWORD" 
          echo "  - DB_NAME"
          echo ""
          echo "You can set them by running: npm run setup-secrets"
          exit 1
        fi
        
        echo "‚úÖ All required GitHub secrets are set"
        
        # Construct the database URL
        DATABASE_URL="postgresql://${DB_USERNAME}:${DB_PASSWORD}@${RDS_ENDPOINT}:${RDS_PORT}/${DB_NAME}"
        
        echo "database_url=$DATABASE_URL" >> $GITHUB_OUTPUT
        echo "‚úÖ Database URL retrieved dynamically from AWS RDS"
        echo "Endpoint: $RDS_ENDPOINT"
        echo "Port: $RDS_PORT"
        echo "Database: $DB_NAME"
        
        # Note: Database connectivity test is skipped because RDS is in private subnets
        # and GitHub Actions runners are outside the VPC. This is expected behavior.
        echo "‚ÑπÔ∏è  Database connectivity test skipped (RDS is in private subnets)"
        echo "‚ÑπÔ∏è  The migration job will test connectivity from within the EKS cluster"
        
    - name: Create or update Secret
      run: |
        # Use the database URL from AWS RDS
        kubectl create secret generic tech-product-api-secret \
          --from-literal=DATABASE_URL="${{ steps.database-url.outputs.database_url }}" \
          --namespace=products-service \
          --dry-run=client -o yaml | kubectl apply -f -
        
    - name: Run database migrations
      run: |
        # Generate migration job
        export DOCKER_IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
        envsubst < k8s/migration-job.yaml > k8s/migration-job-generated.yaml
        
        # Apply migration job
        kubectl apply -f k8s/migration-job-generated.yaml
        
        # Wait for migration job to complete with better error handling
        echo "Waiting for migration job to complete..."
        
        # First, try using kubectl wait with the correct condition
        if kubectl wait --for=condition=complete job/tech-product-api-migration -n products-service --timeout=300s 2>/dev/null; then
          echo "‚úÖ Migration job completed successfully using kubectl wait!"
        else
          echo "kubectl wait timed out, checking job status manually..."
          
          # Alternative: Check if job has succeeded by looking at completion status
          JOB_SUCCEEDED_COUNT=$(kubectl get job tech-product-api-migration -n products-service -o jsonpath='{.status.succeeded}' 2>/dev/null || echo "0")
          if [ "$JOB_SUCCEEDED_COUNT" = "1" ]; then
            echo "‚úÖ Migration job completed successfully (succeeded count: $JOB_SUCCEEDED_COUNT)!"
          else
            echo "Job not completed yet, checking status manually..."
            
            # Check job status every 10 seconds for up to 5 minutes
            for i in {1..30}; do
              echo "Checking migration job status (attempt $i/30)..."
              
              # Get job status - check for both Complete and Succeeded conditions
              JOB_COMPLETE=$(kubectl get job tech-product-api-migration -n products-service -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}' 2>/dev/null || echo "Unknown")
              JOB_SUCCEEDED=$(kubectl get job tech-product-api-migration -n products-service -o jsonpath='{.status.conditions[?(@.type=="Succeeded")].status}' 2>/dev/null || echo "Unknown")
              JOB_FAILED=$(kubectl get job tech-product-api-migration -n products-service -o jsonpath='{.status.conditions[?(@.type=="Failed")].status}' 2>/dev/null || echo "Unknown")
              
              echo "Job Complete status: $JOB_COMPLETE"
              echo "Job Succeeded status: $JOB_SUCCEEDED"
              echo "Job Failed status: $JOB_FAILED"
              
              # Get pod logs if job is running
              POD_NAME=$(kubectl get pods -n products-service -l job-name=tech-product-api-migration -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
              if [ -n "$POD_NAME" ]; then
                echo "Pod name: $POD_NAME"
                echo "Pod status: $(kubectl get pod $POD_NAME -n products-service -o jsonpath='{.status.phase}')"
                echo "Recent logs:"
                kubectl logs $POD_NAME -n products-service --tail=20 || echo "No logs available"
              fi
              
              # Check if job completed successfully
              if [ "$JOB_COMPLETE" = "True" ] || [ "$JOB_SUCCEEDED" = "True" ]; then
                echo "‚úÖ Migration job completed successfully!"
                break
              elif [ "$JOB_FAILED" = "True" ]; then
                echo "‚ùå Migration job failed!"
                echo "Full job description:"
                kubectl describe job tech-product-api-migration -n products-service
                echo "Pod logs:"
                kubectl logs $POD_NAME -n products-service || echo "No logs available"
                exit 1
              fi
              
              # Alternative check: look at succeeded count
              JOB_SUCCEEDED_COUNT=$(kubectl get job tech-product-api-migration -n products-service -o jsonpath='{.status.succeeded}' 2>/dev/null || echo "0")
              if [ "$JOB_SUCCEEDED_COUNT" = "1" ]; then
                echo "‚úÖ Migration job completed successfully (succeeded count: $JOB_SUCCEEDED_COUNT)!"
                break
              fi
                
              # Wait 10 seconds before next check
              sleep 10
            done
            
            # Final check
            if [ "$JOB_COMPLETE" != "True" ] && [ "$JOB_SUCCEEDED" != "True" ]; then
              echo "‚ùå Migration job timed out after 5 minutes!"
              echo "Job description:"
              kubectl describe job tech-product-api-migration -n products-service
              echo "Pod logs:"
              kubectl logs $POD_NAME -n products-service || echo "No logs available"
              exit 1
            fi
          fi
        fi
        
        # Clean up migration job
        kubectl delete -f k8s/migration-job-generated.yaml
        
    - name: Deploy to Kubernetes
      run: |
        # Generate Kubernetes manifests
        envsubst < k8s/deployment.yaml.template > k8s/deployment.yaml
        envsubst < k8s/service.yaml.template > k8s/service.yaml
        envsubst < k8s/ingress.yaml.template > k8s/ingress.yaml
        
        # Apply manifests
        kubectl apply -f k8s/namespace.yaml
        kubectl apply -f k8s/configmap.yaml
        kubectl apply -f k8s/deployment.yaml
        kubectl apply -f k8s/service.yaml
        kubectl apply -f k8s/ingress.yaml
        kubectl apply -f k8s/hpa.yaml
        
        # Wait for deployment to be ready
        kubectl rollout status deployment/tech-product-api -n products-service --timeout=300s
      env:
        DOCKER_IMAGE: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
        SERVICE_NAME: tech-product-api
        SERVICE_PORT: "3001"
        NAMESPACE: products-service
        DOMAIN_NAME: tech-challenge.local 